{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=10>**Quantization Aware Training**</font>\n",
    "+ 以lenet为例介绍量化感知训练的基本流程\n",
    "+ 部署量化感知训练后的网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf verion = 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"tf verion = {tf.__version__}\")\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.layers import InputLayer,Reshape,Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解决GPU内存不足报错，对GPU进行按需分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 归一化输入图片，这样每个像素的值都在[0, 1]之间\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 扩张输入数据维度[height, width, channels(depth)]\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = tf.keras.models.Sequential([\\n        InputLayer(input_shape=(28, 28, 1)),\\n        Conv2D(filters=12, kernel_size=(3, 3),activation='relu'),\\n        MaxPool2D(pool_size=(2,2)),\\n        Flatten(),\\n        Dense(10)\\n    ])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=6,kernel_size=5,strides=(1,1),padding='same',activation='relu',use_bias=False,input_shape=(28,28,1)),\n",
    "        MaxPool2D(pool_size=(3,3),strides=2,padding=\"same\"),\n",
    "        Conv2D(filters=16,kernel_size=5,strides=(1,1),padding='same',activation='relu',use_bias=False),\n",
    "        MaxPool2D(pool_size=(3,3),strides=2,padding=\"same\"),\n",
    "        Flatten(input_shape=(7, 7)),\n",
    "        Dense(120, activation='relu'),\n",
    "        Dense(84, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "'''\n",
    "model = tf.keras.models.Sequential([\n",
    "        InputLayer(input_shape=(28, 28, 1)),\n",
    "        Conv2D(filters=12, kernel_size=(3, 3),activation='relu'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(10)\n",
    "    ])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和评估（普通方式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 model:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 107,764\n",
      "Trainable params: 107,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "==> training\n",
      "1688/1688 [==============================] - 96s 57ms/step - loss: 1.5805 - accuracy: 0.8856 - val_loss: 1.4898 - val_accuracy: 0.9723\n",
      "==> evaluate\n",
      "313/313 - 1s - loss: 1.4924 - accuracy: 0.9708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4923863410949707, 0.97079998254776]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"float32 model:\")\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(\"==> training\")\n",
    "model.fit(x_train, y_train, epochs=1, validation_split=0.1)\n",
    "print(\"==> evaluate\")\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/lenet_normal.hdf5\")\n",
    "model_json = model.to_json()\n",
    "with open('./model/lenet_normal.json', 'w') as file:\n",
    "    file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化感知训练\n",
    "参考(量化感知训练综合指南)[https://tensorflow.google.cn/model_optimization/guide/quantization/training_comprehensive_guide]\n",
    "为了提高模型的准确率，建议：\n",
    "+ 与从头开始训练相比，使用量化感知训练进行微调的效果一般更好\n",
    "+ 尝试“量化某些层”以跳过量化对准确率影响最大的层\n",
    "+ 尝试量化后面的层而不是前面的层\n",
    "+ 避免量化关键层\n",
    "*实验的时候对整个预训练模型进行QAT，测试精度很差，所以只对全连接层进行了QAT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized model:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 120)               94205     \n",
      "_________________________________________________________________\n",
      "quant_dense_1 (QuantizeWrapp (None, 84)                10169     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "quant_dense_2 (QuantizeWrapp (None, 10)                855       \n",
      "=================================================================\n",
      "Total params: 107,779\n",
      "Trainable params: 107,764\n",
      "Non-trainable params: 15\n",
      "_________________________________________________________________\n",
      "==> training\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 1.5719 - accuracy: 0.9311 - val_loss: 1.5292 - val_accuracy: 0.9400\n",
      "==> evaluate\n",
      "313/313 - 2s - loss: 1.5283 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5283045768737793, 0.9506000280380249]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 量化感知训练\n",
    "print(\"quantized model:\")\n",
    "\n",
    "# 量化整个模型\n",
    "#qat_model = tfmot.quantization.keras.quantize_model(pretrained_model)\n",
    "\n",
    "\n",
    "# 量化某些层\n",
    "# Helper function uses `quantize_annotate_layer` to annotate that only the \n",
    "# Dense layers should be quantized.\n",
    "def apply_quantization_to_dense(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "    return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` \n",
    "# to the layers of the model.\n",
    "annotated_model = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_quantization_to_dense,\n",
    ")\n",
    "\n",
    "# Now that the Dense layers are annotated,\n",
    "# `quantize_apply` actually makes the model quantization aware.\n",
    "qat_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "\n",
    "\n",
    "qat_model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "qat_model.summary()\n",
    "\n",
    "print(\"==> training\")\n",
    "x_train_subset = x_train[0:1000]\n",
    "y_train_subset = y_train[0:1000]\n",
    "qat_model.fit(x_train_subset, y_train_subset,\n",
    "              batch_size=500,\n",
    "              epochs=1,\n",
    "              validation_split=0.1)\n",
    "print(\"==> evaluate\")\n",
    "qat_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存量化感知训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.save(\"./model/lenet_qat.hdf5\")\n",
    "qat_model_json = model.to_json()\n",
    "with open('./model/lenet_qat.json', 'w') as file:\n",
    "    file.write(qat_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采用量化感知训练权重更新模型\n",
    "+ 提取QAT后各层的权重(weights,bias)\n",
    "+ 采用这些权重替换预训练模型的相应层的权重\n",
    "+ 评估更新权重后的模型精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in model.layers:\\n    print(i.name)\\nfor i in qat_model.layers:\\n    print(i.name)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型各层的name\n",
    "'''\n",
    "for i in model.layers:\n",
    "    print(i.name)\n",
    "for i in qat_model.layers:\n",
    "    print(i.name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> evaluate\n",
      "313/313 - 4s - loss: 1.4977 - accuracy: 0.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4977458715438843, 0.9641000032424927]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取QAT模型的weights和bias\n",
    "# aa,bb,cc,dd,ee是一些QAT在做fake quantization时用到的值，可以通过netron工具查看\n",
    "\n",
    "weights_0 = qat_model.get_layer('conv2d').get_weights()\n",
    "weights_1 = qat_model.get_layer('conv2d_1').get_weights()\n",
    "bias_2, weights_2, aa, bb, cc, dd, ee = qat_model.get_layer('quant_dense').get_weights()\n",
    "bias_3, weights_3, aa, bb, cc, dd, ee = qat_model.get_layer('quant_dense_1').get_weights()\n",
    "bias_4, weights_4, aa, bb, cc, dd, ee = qat_model.get_layer('quant_dense_2').get_weights()\n",
    "new_weights_2 = []\n",
    "new_weights_3 = []\n",
    "new_weights_4 = []\n",
    "new_weights_2.append(weights_2)\n",
    "new_weights_2.append(bias_2)\n",
    "new_weights_3.append(weights_3)\n",
    "new_weights_3.append(bias_3)\n",
    "new_weights_4.append(weights_4)\n",
    "new_weights_4.append(bias_4)\n",
    "\n",
    "# 把权重覆盖到相应的层\n",
    "opt_model = load_model(\"./model/lenet_normal.hdf5\") \n",
    "opt_model.get_layer('conv2d').set_weights(weights_0)\n",
    "opt_model.get_layer('conv2d_1').set_weights(weights_1)\n",
    "opt_model.get_layer('dense').set_weights(new_weights_2)\n",
    "opt_model.get_layer('dense_1').set_weights(new_weights_3)\n",
    "opt_model.get_layer('dense_2').set_weights(new_weights_4)\n",
    "print(\"==> evaluate\")\n",
    "opt_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存QAT优化后模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model.save(\"./model/lenet_opt.hdf5\")\n",
    "opt_model_json = opt_model.to_json()\n",
    "with open('./model/lenet_opt.json', 'w') as file:\n",
    "    file.write(opt_model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将keras模型转换为TFLite模型，并执行量化\n",
    "我们后续要对TFLite模型执行训练后量化，从而评估经过QAT后的模型在量化后精度损失更小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert TFLite done\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train.astype(np.float32)).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "        yield [input_value]\n",
    "\n",
    "# 将原始keras模型转换为tflite模型，并执行量化（float fallback quantization, tf2.3之后才支持full integer quant）\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "opt_converter = tf.lite.TFLiteConverter.from_keras_model(opt_model)\n",
    "opt_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "opt_converter.representative_dataset = representative_data_gen\n",
    "opt_quantized_tflite_model = opt_converter.convert()\n",
    "print('convert TFLite done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存TFLite训练后量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/lenet_normal.tflite', 'wb') as file:\n",
    "    file.write(quantized_tflite_model)\n",
    "with open('./model/lenet_opt.tflite', 'wb') as file:\n",
    "    file.write(opt_quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估QAT对量化带来的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9706\n",
      "QAT Optimized Quant TFLite test_accuracy: 0.9635\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(x_test):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == y_test).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "opt_interpreter = tf.lite.Interpreter(model_content=opt_quantized_tflite_model)\n",
    "opt_interpreter.allocate_tensors()\n",
    "opt_test_accuracy = evaluate_model(opt_interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('QAT Optimized Quant TFLite test_accuracy:', opt_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
