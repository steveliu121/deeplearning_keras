{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=10>**Magnitude-based Pruning**</font>\n",
    "\n",
    "+ 构建、训练lenet网络\n",
    "+ 以lenet为例介绍基于权重幅值的剪枝基本流程\n",
    "+ 训练剪枝后的模型\n",
    "+ 比较模型剪枝前后的推理速度、精度差异\n",
    "+ 比较量化后的预训练模型和量化后的剪枝训练后的模型的推理速度、精度差异(本文不描述了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf verion = 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"tf verion = {tf.__version__}\")\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.layers import InputLayer,Reshape,Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*解决GPU内存不足报错，对GPU进行按需分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小工具：查看一下各层的saprsity**\n",
    "\n",
    "只有两个conv和三个dense层有weights，其中dense层还有biases\n",
    "通过打印出的结果可以看到:\n",
    "+ 所有的bias都没有剪枝\n",
    "+ 剪枝是按层进行的，每层都剪掉了80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(weights):\n",
    "    return 1.0 - np.count_nonzero(weights) / float(weights.size)\n",
    "\n",
    "def list_sparsity(_model):\n",
    "    for layer in _model.layers:\n",
    "        for weight in layer.get_weights():\n",
    "            '''\n",
    "            print(np.allclose(\n",
    "                target_sparsity, get_sparsity(tf.keras.backend.get_value(weight)), \n",
    "                rtol=1e-6, atol=1e-6)\n",
    "            )\n",
    "            '''\n",
    "            print('%s sparsity:%f' %(layer.name, get_sparsity(tf.keras.backend.get_value(weight))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建、训练Lenet网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 归一化输入图片，这样每个像素的值都在[0, 1]之间\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 扩张输入数据维度[height, width, channels(depth)]\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 model:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 107,764\n",
      "Trainable params: 107,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=6,kernel_size=5,strides=(1,1),padding='same',activation='relu',use_bias=False,input_shape=(28,28,1)),\n",
    "        MaxPool2D(pool_size=(3,3),strides=2,padding=\"same\"),\n",
    "        Conv2D(filters=16,kernel_size=5,strides=(1,1),padding='same',activation='relu',use_bias=False),\n",
    "        MaxPool2D(pool_size=(3,3),strides=2,padding=\"same\"),\n",
    "        Flatten(input_shape=(7, 7)),\n",
    "        Dense(120, activation='relu'),\n",
    "        Dense(84, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "print(\"float32 model:\")\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training\n",
      "1688/1688 [==============================] - 96s 57ms/step - loss: 1.6175 - accuracy: 0.8484 - val_loss: 1.4940 - val_accuracy: 0.9673\n",
      "==> evaluate\n",
      "313/313 - 1s - loss: 1.4989 - accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "print(\"==> training\")\n",
    "model.fit(x_train, y_train, epochs=1, validation_split=0.1)\n",
    "print(\"==> evaluate\")\n",
    "baseline_model_accuracy = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/lenet_normal.hdf5\")\n",
    "model_json = model.to_json()\n",
    "with open('./model/lenet_normal.json', 'w') as file:\n",
    "    file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络剪枝(magnitude-base pruning)&Fine-tune\n",
    "开始修剪掉50%，最终修剪掉80%(80%的权重为0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 采用渐进的修剪方式(tfmot.sparsity.keras.PolynomialDecay)，不要修剪的太频繁，在修剪过程中给模型留出修剪后恢复精度的充裕时间(tfmot.sparsity.keras.ConstantSparsity一步修剪到位)\n",
    "+ 只修剪dense层，不修剪分类头 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载预训练网络，以此为基础进行剪枝，剪枝后的model_for_pruning和model_for_export都引用了这一网络，会造成网络权重数据的覆盖，所以我们这边加载一个临时的网络用来剪枝，后续引用它时需要谨慎**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = load_model(\"./model/lenet_normal.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建剪枝网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/steve_liu/miniconda3/envs/pDL/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:194: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 120)               188282    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 84)                20246     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 211,928\n",
      "Trainable params: 107,764\n",
      "Non-trainable params: 104,164\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1  # 10% of training set will be used for validation set.\n",
    "\n",
    "num_images = x_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule':\n",
    "    tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                         final_sparsity=0.80,\n",
    "                                         begin_step=0,\n",
    "                                         end_step=end_step)\n",
    "}\n",
    "\n",
    "# 对整个模型施加修剪\n",
    "#model_for_pruning = prune_low_magnitude(pretrained_model, **pruning_params)\n",
    "\n",
    "\n",
    "# 只修剪我们指定的层\n",
    "def apply_pruning_do_custom_layers(layer):\n",
    "    if layer.name == \"dense\" or layer.name == \"dense_1\":\n",
    "        return prune_low_magnitude(layer, **pruning_params)\n",
    "    return layer\n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    pretrained_model, clone_function=apply_pruning_do_custom_layers,)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune剪枝网络&评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training\n",
      "Epoch 1/2\n",
      "422/422 [==============================] - 38s 90ms/step - loss: 1.5019 - accuracy: 0.9603 - val_loss: 1.4871 - val_accuracy: 0.9743\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 39s 93ms/step - loss: 1.4918 - accuracy: 0.9706 - val_loss: 1.4802 - val_accuracy: 0.9812\n",
      "==> evaluate\n",
      "313/313 - 2s - loss: 1.4819 - accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "print(\"==> training\")\n",
    "model_for_pruning.fit(x_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "print(\"==> evaluate\")\n",
    "model_for_pruning_accuracy = model_for_pruning.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## strip prune wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               94200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 107,764\n",
      "Trainable params: 107,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看一下剪枝strip后模型各层的sparsity\n",
    "\n",
    "只有两个conv和三个dense层有weights，其中dense层还有biases\n",
    "通过打印出的结果可以看到:\n",
    "+ 所有的bias都没有剪枝\n",
    "+ 剪枝是按层进行的，每层都剪掉了80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d sparsity:0.000000\n",
      "conv2d_1 sparsity:0.000000\n",
      "dense sparsity:0.799957\n",
      "dense sparsity:0.000000\n",
      "dense_1 sparsity:0.800000\n",
      "dense_1 sparsity:0.000000\n",
      "dense_2 sparsity:0.000000\n",
      "dense_2 sparsity:0.000000\n"
     ]
    }
   ],
   "source": [
    "list_sparsity(model_for_export)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存strip后的Fine-tune模型\n",
    "+ 模型的压缩率得到了提升：\n",
    "由于有80%的权重被我们剪掉了(值为0)，因此模型压缩后可以获得更小的体积\n",
    "采用\"bz2\"压缩，压缩前预训练模型和剪枝后模型大小都是1338456bytes，压缩后分别为1247222bytes和942522bytes。可以看出剪枝后模型小了很多。\n",
    "+ 网络的运行时间得到了减少："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export.save(\"./model/lenet_prune.hdf5\")\n",
    "model_for_export_json = model_for_export.to_json()\n",
    "with open('./model/lenet_prune.json', 'w') as file:\n",
    "    file.write(model_for_export_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化Fine-tune模型\n",
    "+ 将预训练模型和Fine-tune模型转换为TFLite格式\n",
    "+ 量化模型\n",
    "+ 比较剪枝前后的模型在量化后的精度差异\n",
    "+ 查看量化后的Fine-tune模型的sparsity是否还是80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换和量化：预训练模型和Fine-tune模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert TFLite done\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train.astype(np.float32)).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "        yield [input_value]\n",
    "\n",
    "# 将原始keras模型转换为tflite模型，并执行量化（float fallback quantization, tf2.3之后才支持full integer quant）\n",
    "base_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "base_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "base_converter.representative_dataset = representative_data_gen\n",
    "base_tflite_model = base_converter.convert()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "print('convert TFLite done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存TFLite训练后量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/lenet_normal.tflite', 'wb') as file:\n",
    "    file.write(base_tflite_model)\n",
    "with open('./model/lenet_prune.tflite', 'wb') as file:\n",
    "    file.write(pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估预训练模型和Fine-tune模型量化后的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quantized TFLite model accuracy compare:===>\n",
      "Base(pre-trained) TFLite test_accuracy: 0.9625\n",
      "Pruned TFLite test_accuracy: 0.9809\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(x_test):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == y_test).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=base_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "prune_interpreter = tf.lite.Interpreter(model_content=pruned_tflite_model)\n",
    "prune_interpreter.allocate_tensors()\n",
    "prune_test_accuracy = evaluate_model(prune_interpreter)\n",
    "\n",
    "print(\"Quantized TFLite model accuracy compare:===>\")\n",
    "print('Base(pre-trained) TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TFLite test_accuracy:', prune_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看剪枝训练量化后模型各层的信息，从而找出权重所在层的index，便于我们提取权重**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_input_int8\n",
      "[ 1 28 28  1]\n",
      "(0.003921568859368563, -128)\n",
      "0\n",
      "sequential/dense/BiasAdd/ReadVariableOp\n",
      "[120]\n",
      "(9.454518294660375e-05, 0)\n",
      "1\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "[84]\n",
      "(0.00023016009072307497, 0)\n",
      "2\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp\n",
      "[10]\n",
      "(0.00030758496723137796, 0)\n",
      "3\n",
      "sequential/flatten/Const\n",
      "[2]\n",
      "(0.0, 0)\n",
      "4\n",
      "sequential/dense/MatMul\n",
      "[120 784]\n",
      "(0.0029811603017151356, 0)\n",
      "5\n",
      "sequential/dense_1/MatMul\n",
      "[ 84 120]\n",
      "(0.0029013315215706825, 0)\n",
      "6\n",
      "sequential/dense_2/MatMul\n",
      "[10 84]\n",
      "(0.004509610589593649, 0)\n",
      "7\n",
      "sequential/conv2d/Conv2D\n",
      "[6]\n",
      "(0.0, 0)\n",
      "8\n",
      "sequential/conv2d/Conv2D1\n",
      "[6 5 5 1]\n",
      "(0.0, 0)\n",
      "9\n",
      "sequential/conv2d_1/Conv2D\n",
      "[16]\n",
      "(0.0, 0)\n",
      "10\n",
      "sequential/conv2d_1/Conv2D1\n",
      "[16  5  5  6]\n",
      "(0.0, 0)\n",
      "11\n",
      "sequential/conv2d/Relu;sequential/conv2d/Conv2D\n",
      "[ 1 28 28  6]\n",
      "(0.017847036942839622, -128)\n",
      "12\n",
      "sequential/max_pooling2d/MaxPool\n",
      "[ 1 14 14  6]\n",
      "(0.017847036942839622, -128)\n",
      "13\n",
      "sequential/conv2d_1/Relu;sequential/conv2d_1/Conv2D\n",
      "[ 1 14 14 16]\n",
      "(0.03171422332525253, -128)\n",
      "14\n",
      "sequential/max_pooling2d_1/MaxPool\n",
      "[ 1  7  7 16]\n",
      "(0.03171422332525253, -128)\n",
      "15\n",
      "sequential/flatten/Reshape\n",
      "[  1 784]\n",
      "(0.03171422332525253, -128)\n",
      "16\n",
      "sequential/dense/Relu;sequential/dense/BiasAdd\n",
      "[  1 120]\n",
      "(0.07932912558317184, -128)\n",
      "17\n",
      "sequential/dense_1/Relu;sequential/dense_1/BiasAdd\n",
      "[ 1 84]\n",
      "(0.0682065486907959, -128)\n",
      "18\n",
      "sequential/dense_2/BiasAdd\n",
      "[ 1 10]\n",
      "(0.28952500224113464, -1)\n",
      "19\n",
      "Identity_int8\n",
      "[ 1 10]\n",
      "(0.00390625, -128)\n",
      "20\n",
      "conv2d_input\n",
      "[ 1 28 28  1]\n",
      "(0.0, 0)\n",
      "21\n",
      "Identity\n",
      "[ 1 10]\n",
      "(0.0, 0)\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "all_layer_details = prune_interpreter.get_tensor_details()\n",
    "for layer in all_layer_details:\n",
    "    print(layer['name'])\n",
    "    print(layer['shape'])\n",
    "    print(layer['quantization'])\n",
    "    print(layer['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计剪枝量化后模型的稀疏度(sparsity)\n",
    "+ 通过前面提取的信息可以知道权重所处的层，统计一下量化后权重的sparsity，结果显示量化没有改变sparsity，此处也即：量化后的权重层仍有80%的权重值是0.保持sparsity量化后不变的本质是：量化前0权重(float)量化为0权重(uint8)。根据我们的量化公式r=s(q - z)可知要想保证这一点，zero_point应该为0，进一步可以推导出min(r)应该为0，即权重的最小值必须是0。此处应该是特殊情况\n",
    "+ 目前没有发现有资料说明量化不改变sparsity\n",
    "+ 剪枝的使用应该更侧重于提高模型的可压缩性，便于在边缘设备上的部署。tensorflow给出的例子上也是只关注了模型的可压缩度（譬如lenet网络在剪枝后稀疏度为80%，通过zip压缩可以获得3倍的压缩效果，keras转换为tflite后再量化加上之前的剪枝一共可以获得10倍的压缩效果），没有关注模型的inference时间有无改善。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense sparsity:0.799957\n",
      "dense1 sparsity:0.800000\n",
      "dense2 sparsity:0.002381\n",
      "conv2d sparsity:0.006667\n",
      "conv2d_1 sparsity:0.008333\n"
     ]
    }
   ],
   "source": [
    "# layers: [5]:dense weights, [6]:dense1 weights, [7]:dense2 weights, [9]conv2d weights, [11]:conv2d_1 weights\n",
    "weight_layer_index = [5, 6 ,7 ,9 ,11]\n",
    "weight_layer_name = [\"dense\", \"dense1\" ,\"dense2\" ,\"conv2d\" ,\"conv2d_1\"]\n",
    "weight_layers = {\"dense\" : 5, \"dense1\" : 6,\"dense2\" : 7, \"conv2d\" : 9, \"conv2d_1\" : 11}\n",
    "\n",
    "for name, index in weight_layers.items():\n",
    "    weight = prune_interpreter.get_tensor(index)\n",
    "    print('%s sparsity:%f' %(name, get_sparsity(weight)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
