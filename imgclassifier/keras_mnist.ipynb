{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采用keras库搭建简单神经网络对MNIST数据集分类\n",
    "\n",
    "## 代码流程\n",
    "+ 加载MNIST数据集（首次使用MNIST数据集需要下载）\n",
    "+ 量化数据，raw pixel [0, 255] --> [0, 1.0]\n",
    "+ 划分训练集和测试集\n",
    "+ 将label转换为one-hot格式\n",
    "+ 构建一个三层全连接神经网络(Dense)(不包括输入层)，两个隐层层采用sigmod激活，输出层采用softmax进行10分类\n",
    "\n",
    "## 注意\n",
    "+ 输入是灰度图像，只有一个通道，分辨率是\"28 x 28\"\n",
    "+ 为了简单示范起见，我们将数据集划分为\"trainning set\"和\"testing set\"，并将\"testing set\"当做\"validation set\"使用。正式使用中需要从\"trainning set\"再划分出\"validation set\"\n",
    "+ 优化算法采用\"mini-batch SGD\"，\"learning_rate=0.01\"，loss采用\"categorical cross entropy\"，\"epoch=100\"，　\"batch_size=128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "[INFO] load MNIST dataset done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "'''\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "            help=\"path to the output loss/accuracy plot\")\n",
    "args = vars(ap.parse_args())\n",
    "'''\n",
    "\n",
    "'''\n",
    "加载\"mnist_784\"数据集，若\"data_home\"目录下不存在需要下载\n",
    "'''\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "dataset = datasets.fetch_openml(name=\"mnist_784\", \n",
    "                                data_home=os.path.abspath(os.path.join(os.getcwd(), \"../imgdatasets\")))\n",
    "print(\"[INFO] load MNIST dataset done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] split trainning&testing dataset...\n",
      "[INFO] transform labels to one-hot...\n",
      "[INFO] structure a Dense network architecture...\n",
      "[INFO] trainning network...\n",
      "Epoch 1/20\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 1.0237 - accuracy: 0.7583 - val_loss: 0.5561 - val_accuracy: 0.8604\n",
      "Epoch 2/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.4602 - accuracy: 0.8793 - val_loss: 0.4041 - val_accuracy: 0.8885\n",
      "Epoch 3/20\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.3696 - accuracy: 0.8997 - val_loss: 0.3527 - val_accuracy: 0.9005\n",
      "Epoch 4/20\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.3280 - accuracy: 0.9086 - val_loss: 0.3203 - val_accuracy: 0.9090\n",
      "Epoch 5/20\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.3014 - accuracy: 0.9159 - val_loss: 0.2989 - val_accuracy: 0.9130\n",
      "Epoch 6/20\n",
      "411/411 [==============================] - 4s 11ms/step - loss: 0.2816 - accuracy: 0.9211 - val_loss: 0.2822 - val_accuracy: 0.9178\n",
      "Epoch 7/20\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.2657 - accuracy: 0.9251 - val_loss: 0.2679 - val_accuracy: 0.9222\n",
      "Epoch 8/20\n",
      "411/411 [==============================] - 4s 11ms/step - loss: 0.2520 - accuracy: 0.9294 - val_loss: 0.2604 - val_accuracy: 0.9240\n",
      "Epoch 9/20\n",
      "411/411 [==============================] - 5s 12ms/step - loss: 0.2400 - accuracy: 0.9324 - val_loss: 0.2472 - val_accuracy: 0.9273\n",
      "Epoch 10/20\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.2293 - accuracy: 0.9349 - val_loss: 0.2379 - val_accuracy: 0.9317\n",
      "Epoch 11/20\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.2197 - accuracy: 0.9377 - val_loss: 0.2298 - val_accuracy: 0.9333\n",
      "Epoch 12/20\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.2110 - accuracy: 0.9400 - val_loss: 0.2223 - val_accuracy: 0.9345\n",
      "Epoch 13/20\n",
      "411/411 [==============================] - 4s 9ms/step - loss: 0.2030 - accuracy: 0.9428 - val_loss: 0.2165 - val_accuracy: 0.9378\n",
      "Epoch 14/20\n",
      "411/411 [==============================] - 4s 10ms/step - loss: 0.1956 - accuracy: 0.9449 - val_loss: 0.2066 - val_accuracy: 0.9405\n",
      "Epoch 15/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1887 - accuracy: 0.9463 - val_loss: 0.2016 - val_accuracy: 0.9413\n",
      "Epoch 16/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1823 - accuracy: 0.9481 - val_loss: 0.1977 - val_accuracy: 0.9415\n",
      "Epoch 17/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1763 - accuracy: 0.9500 - val_loss: 0.1925 - val_accuracy: 0.9438\n",
      "Epoch 18/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1706 - accuracy: 0.9514 - val_loss: 0.1859 - val_accuracy: 0.9443\n",
      "Epoch 19/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1652 - accuracy: 0.9529 - val_loss: 0.1827 - val_accuracy: 0.9467\n",
      "Epoch 20/20\n",
      "411/411 [==============================] - 3s 8ms/step - loss: 0.1605 - accuracy: 0.9544 - val_loss: 0.1761 - val_accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] split trainning&testing dataset...\")\n",
    "'''\n",
    "将数据raw pixel[0, 255]量化[0, 1.0]，并划分\"trainning set\"和\"testing set\"\n",
    "random_state用来保证每次随机划分\"dataset\"时用的随机数是同一组一样的\n",
    "stratify表示\"trainning set\"和\"testing set\"的数据分布都同整个dataset相同（也可以设置成同）\n",
    "'''\n",
    "data = dataset.data.astype(\"float\") / 255.0\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    dataset.target, test_size=0.25, random_state = 42, stratify=dataset.target)\n",
    "\n",
    "print(\"[INFO] transform labels to one-hot...\")\n",
    "'''\n",
    "将标签转换为one-hot格式\n",
    "'''\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)\n",
    "\n",
    "print(\"[INFO] structure a Dense network architecture...\")\n",
    "model = Sequential()\n",
    "'''\n",
    "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "'''\n",
    "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "'''\n",
    "加载同一组权重，保证不同optimization的初始权重相同，具有可比较意义\n",
    "'''\n",
    "model.load_weights(\"./weights/keras_mnist_weights.hd5\")\n",
    "\n",
    "print(\"[INFO] trainning network...\")\n",
    "sgd = SGD(0.01)\n",
    "'''\n",
    "metrics表示训练时同时衡量它的\"accuracy\"（此处）指标，metrics只参与衡量，不参与优化计算\n",
    "'''\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "             metrics=[\"accuracy\"])\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "             epochs=20, batch_size=128)\n",
    "\n",
    "#model.save_weights(\"./keras_mnist_weights.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1726\n",
      "           1       0.97      0.98      0.97      1969\n",
      "           2       0.95      0.94      0.95      1748\n",
      "           3       0.94      0.93      0.93      1785\n",
      "           4       0.92      0.96      0.94      1706\n",
      "           5       0.93      0.93      0.93      1578\n",
      "           6       0.95      0.97      0.96      1719\n",
      "           7       0.96      0.96      0.96      1823\n",
      "           8       0.93      0.93      0.93      1706\n",
      "           9       0.94      0.90      0.92      1740\n",
      "\n",
      "    accuracy                           0.95     17500\n",
      "   macro avg       0.95      0.95      0.95     17500\n",
      "weighted avg       0.95      0.95      0.95     17500\n",
      "\n",
      "(17500, 10) (17500, 10)\n",
      "17500\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "'''\n",
    "testY.shape=[17500, 10]，共有17500张图片，每张图片的标签是一个dimension=10的one-hot向量\n",
    "testY.argmax(axis=1)返回的是每个one-hot向量中最大的数的index，one-hot只有一个元素是1，其余都是0\n",
    "其实就是返回的这个数字的原始label，譬如[0,0,0,0,0,0,1,0,0,0,0]--->6\n",
    "predictions同上\n",
    "target_names是数据集的原始label\n",
    "'''\n",
    "predictions = model.predict(testX, batch_size=128)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "     predictions.argmax(axis=1),\n",
    "     target_names=[str(x) for x in lb.classes_]))\n",
    "print(testY.shape, predictions.shape)\n",
    "print(testY.shape[0])\n",
    "print(testY.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./results/mnist_trainning_result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
