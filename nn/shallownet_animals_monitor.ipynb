{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存训练过程的metrics数据\n",
    "保存每个epoch得到的\"train_loss/accuracy\"和\"validation_loss/accuracy\"，并实时绘制图形，方便我们根据图形来判断训练的状态，做出及时的调整 譬如发生overfitting(可能由于learning rate太大，网络太冗余导致)，判断何时停止training。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imgpreprocess.imgtoarray import ImgToArray\n",
    "from imgpreprocess.imgresize import ImgResize\n",
    "from imgdatasets.imgload import ImgLoad\n",
    "from nn.conv.shallownet import ShallowNet\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from callbacks.trainingmonitor import TrainingMonitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nap = argparse.ArgumentParser()\\nap.add_argument(\"-d\", \"--dataset\", required=True,\\n               help=\"path to input dataset\")\\nap.add_argument(\"-m\", \"--model\", required=True,\\n               help=\"path to output model\")\\nargs = vars(ap.parse_args())\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "               help=\"path to input dataset\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "               help=\"path to output model\")\n",
    "args = vars(ap.parse_args())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] load images dnoe...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "#imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "imagePaths = list(paths.list_images(\"../imgdatasets/animals3\"))\n",
    "print(\"[INFO] load images dnoe...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] images preprocessing...\n",
      "[INFO] images preprocess done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] images preprocessing...\")\n",
    "resize = ImgResize(32, 32)\n",
    "imgtoarray = ImgToArray()\n",
    "\n",
    "imgload = ImgLoad(preprocessors=[resize, imgtoarray])\n",
    "(data, labels) = imgload.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "print(\"[INFO] images preprocess done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train test dataset split\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] train test dataset split\")\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.25, random_state=42, stratify=labels)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "model = ShallowNet.build(width=32, height=32, depth=3, classes=3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] trainning network...\n",
      "Epoch 1/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.9071 - accuracy: 0.5949 - val_loss: 0.8751 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 13s 60ms/step - loss: 0.8425 - accuracy: 0.6355 - val_loss: 0.8487 - val_accuracy: 0.6346\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 13s 60ms/step - loss: 0.8121 - accuracy: 0.6556 - val_loss: 0.8267 - val_accuracy: 0.6431\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 13s 61ms/step - loss: 0.7869 - accuracy: 0.6644 - val_loss: 0.8069 - val_accuracy: 0.6570\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 14s 65ms/step - loss: 0.7686 - accuracy: 0.6741 - val_loss: 0.7879 - val_accuracy: 0.6735\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 15s 72ms/step - loss: 0.7472 - accuracy: 0.6843 - val_loss: 0.7752 - val_accuracy: 0.6758\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.7272 - accuracy: 0.6935 - val_loss: 0.7645 - val_accuracy: 0.6762\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.7060 - accuracy: 0.7040 - val_loss: 0.7395 - val_accuracy: 0.6991\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 11s 55ms/step - loss: 0.6870 - accuracy: 0.7226 - val_loss: 0.7337 - val_accuracy: 0.6991\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 13s 60ms/step - loss: 0.6672 - accuracy: 0.7273 - val_loss: 0.7478 - val_accuracy: 0.6955\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 12s 58ms/step - loss: 0.6503 - accuracy: 0.7361 - val_loss: 0.7073 - val_accuracy: 0.7201\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 11s 53ms/step - loss: 0.6323 - accuracy: 0.7453 - val_loss: 0.7175 - val_accuracy: 0.7107\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.6158 - accuracy: 0.7543 - val_loss: 0.6909 - val_accuracy: 0.7246\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 16s 76ms/step - loss: 0.6030 - accuracy: 0.7640 - val_loss: 0.6919 - val_accuracy: 0.7210\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.5903 - accuracy: 0.7691 - val_loss: 0.6887 - val_accuracy: 0.7215\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.5776 - accuracy: 0.7737 - val_loss: 0.6774 - val_accuracy: 0.7264\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 14s 64ms/step - loss: 0.5647 - accuracy: 0.7792 - val_loss: 0.7141 - val_accuracy: 0.7062\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.5540 - accuracy: 0.7850 - val_loss: 0.6667 - val_accuracy: 0.7309\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 12s 57ms/step - loss: 0.5423 - accuracy: 0.7880 - val_loss: 0.6637 - val_accuracy: 0.7403\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 13s 61ms/step - loss: 0.5329 - accuracy: 0.7946 - val_loss: 0.6688 - val_accuracy: 0.7277\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 13s 63ms/step - loss: 0.5262 - accuracy: 0.7979 - val_loss: 0.6868 - val_accuracy: 0.7138\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 15s 73ms/step - loss: 0.5159 - accuracy: 0.8003 - val_loss: 0.6658 - val_accuracy: 0.7421\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 14s 65ms/step - loss: 0.5092 - accuracy: 0.8025 - val_loss: 0.6913 - val_accuracy: 0.7147\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 15s 70ms/step - loss: 0.5000 - accuracy: 0.8058 - val_loss: 0.6855 - val_accuracy: 0.7291\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 16s 76ms/step - loss: 0.4932 - accuracy: 0.8100 - val_loss: 0.6697 - val_accuracy: 0.7318\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 14s 64ms/step - loss: 0.4842 - accuracy: 0.8177 - val_loss: 0.6651 - val_accuracy: 0.7331\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.4779 - accuracy: 0.8186 - val_loss: 0.6763 - val_accuracy: 0.7192\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 12s 58ms/step - loss: 0.4710 - accuracy: 0.8237 - val_loss: 0.6690 - val_accuracy: 0.7304\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.4655 - accuracy: 0.8225 - val_loss: 0.6992 - val_accuracy: 0.7223\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.4607 - accuracy: 0.8273 - val_loss: 0.6686 - val_accuracy: 0.7371\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 14s 68ms/step - loss: 0.4524 - accuracy: 0.8286 - val_loss: 0.6794 - val_accuracy: 0.7264\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 14s 65ms/step - loss: 0.4456 - accuracy: 0.8321 - val_loss: 0.6850 - val_accuracy: 0.7241\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.4394 - accuracy: 0.8322 - val_loss: 0.6882 - val_accuracy: 0.7326\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 14s 68ms/step - loss: 0.4341 - accuracy: 0.8337 - val_loss: 0.6696 - val_accuracy: 0.7300\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 16s 77ms/step - loss: 0.4295 - accuracy: 0.8386 - val_loss: 0.6737 - val_accuracy: 0.7376\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.4218 - accuracy: 0.8416 - val_loss: 0.6841 - val_accuracy: 0.7385\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.4149 - accuracy: 0.8442 - val_loss: 0.6783 - val_accuracy: 0.7429\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.4087 - accuracy: 0.8464 - val_loss: 0.6803 - val_accuracy: 0.7429\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 13s 63ms/step - loss: 0.4020 - accuracy: 0.8516 - val_loss: 0.7140 - val_accuracy: 0.7291\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 14s 66ms/step - loss: 0.3977 - accuracy: 0.8500 - val_loss: 0.7446 - val_accuracy: 0.7295\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.3937 - accuracy: 0.8536 - val_loss: 0.7002 - val_accuracy: 0.7112\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 12s 57ms/step - loss: 0.3870 - accuracy: 0.8580 - val_loss: 0.6819 - val_accuracy: 0.7362\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 13s 63ms/step - loss: 0.3843 - accuracy: 0.8610 - val_loss: 0.6917 - val_accuracy: 0.7255\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 13s 60ms/step - loss: 0.3769 - accuracy: 0.8627 - val_loss: 0.7128 - val_accuracy: 0.7362\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 14s 68ms/step - loss: 0.3707 - accuracy: 0.8652 - val_loss: 0.7389 - val_accuracy: 0.7264\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 12s 57ms/step - loss: 0.3665 - accuracy: 0.8680 - val_loss: 0.7070 - val_accuracy: 0.7237\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 13s 61ms/step - loss: 0.3604 - accuracy: 0.8692 - val_loss: 0.6953 - val_accuracy: 0.7215\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 14s 65ms/step - loss: 0.3566 - accuracy: 0.8691 - val_loss: 0.7233 - val_accuracy: 0.7349\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 13s 62ms/step - loss: 0.3495 - accuracy: 0.8737 - val_loss: 0.7068 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.3459 - accuracy: 0.8731 - val_loss: 0.7354 - val_accuracy: 0.7120\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.3423 - accuracy: 0.8773 - val_loss: 0.7147 - val_accuracy: 0.7134\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 10s 50ms/step - loss: 0.3336 - accuracy: 0.8771 - val_loss: 0.7228 - val_accuracy: 0.7349\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.3314 - accuracy: 0.8821 - val_loss: 0.7183 - val_accuracy: 0.7259\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 10s 46ms/step - loss: 0.3249 - accuracy: 0.8874 - val_loss: 0.7657 - val_accuracy: 0.7318\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 11s 51ms/step - loss: 0.3234 - accuracy: 0.8873 - val_loss: 0.7301 - val_accuracy: 0.7210\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 10s 46ms/step - loss: 0.3157 - accuracy: 0.8904 - val_loss: 0.7218 - val_accuracy: 0.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.3108 - accuracy: 0.8904 - val_loss: 0.7337 - val_accuracy: 0.7120\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.3077 - accuracy: 0.8927 - val_loss: 0.7349 - val_accuracy: 0.7125\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.3069 - accuracy: 0.8945 - val_loss: 0.7339 - val_accuracy: 0.7282\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 11s 53ms/step - loss: 0.2979 - accuracy: 0.8980 - val_loss: 0.7389 - val_accuracy: 0.7179\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.2945 - accuracy: 0.9019 - val_loss: 0.7489 - val_accuracy: 0.7331\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 13s 62ms/step - loss: 0.2891 - accuracy: 0.9046 - val_loss: 0.7448 - val_accuracy: 0.7264\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 13s 61ms/step - loss: 0.2847 - accuracy: 0.9061 - val_loss: 0.7604 - val_accuracy: 0.7331\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.2818 - accuracy: 0.9061 - val_loss: 0.7684 - val_accuracy: 0.7179\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.2765 - accuracy: 0.9086 - val_loss: 0.7467 - val_accuracy: 0.7237\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.2710 - accuracy: 0.9145 - val_loss: 0.7812 - val_accuracy: 0.7291\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.2675 - accuracy: 0.9124 - val_loss: 0.7795 - val_accuracy: 0.7147\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.2625 - accuracy: 0.9183 - val_loss: 0.7555 - val_accuracy: 0.7192\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.2600 - accuracy: 0.9157 - val_loss: 0.7747 - val_accuracy: 0.7255\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.2552 - accuracy: 0.9180 - val_loss: 0.7717 - val_accuracy: 0.7188\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 9s 44ms/step - loss: 0.2509 - accuracy: 0.9227 - val_loss: 0.7768 - val_accuracy: 0.7206\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 9s 44ms/step - loss: 0.2474 - accuracy: 0.9222 - val_loss: 0.7815 - val_accuracy: 0.7098\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 11s 51ms/step - loss: 0.2425 - accuracy: 0.9273 - val_loss: 0.8011 - val_accuracy: 0.7152\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 9s 41ms/step - loss: 0.2386 - accuracy: 0.9276 - val_loss: 0.7850 - val_accuracy: 0.7112\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.2355 - accuracy: 0.9292 - val_loss: 0.7801 - val_accuracy: 0.7206\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 12s 55ms/step - loss: 0.2292 - accuracy: 0.9345 - val_loss: 0.8096 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.2263 - accuracy: 0.9351 - val_loss: 0.7893 - val_accuracy: 0.7232\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.2241 - accuracy: 0.9325 - val_loss: 0.8014 - val_accuracy: 0.7206\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 16s 74ms/step - loss: 0.2169 - accuracy: 0.9388 - val_loss: 0.8040 - val_accuracy: 0.7188\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 14s 66ms/step - loss: 0.2161 - accuracy: 0.9397 - val_loss: 0.8159 - val_accuracy: 0.7076\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.2149 - accuracy: 0.9394 - val_loss: 0.8126 - val_accuracy: 0.7170\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 10s 50ms/step - loss: 0.2083 - accuracy: 0.9410 - val_loss: 0.8160 - val_accuracy: 0.7192\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 11s 53ms/step - loss: 0.2044 - accuracy: 0.9455 - val_loss: 0.8513 - val_accuracy: 0.7219\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.2037 - accuracy: 0.9415 - val_loss: 0.8149 - val_accuracy: 0.7215\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.1998 - accuracy: 0.9449 - val_loss: 0.8276 - val_accuracy: 0.7228\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 13s 60ms/step - loss: 0.1973 - accuracy: 0.9448 - val_loss: 0.8237 - val_accuracy: 0.7282\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 10s 49ms/step - loss: 0.1907 - accuracy: 0.9510 - val_loss: 0.8727 - val_accuracy: 0.7246\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 10s 50ms/step - loss: 0.1892 - accuracy: 0.9515 - val_loss: 0.8482 - val_accuracy: 0.7246\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 7s 34ms/step - loss: 0.1871 - accuracy: 0.9524 - val_loss: 0.9096 - val_accuracy: 0.7223\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 10s 45ms/step - loss: 0.1842 - accuracy: 0.9518 - val_loss: 0.8588 - val_accuracy: 0.7268\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 11s 51ms/step - loss: 0.1791 - accuracy: 0.9543 - val_loss: 0.8643 - val_accuracy: 0.7058\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 11s 52ms/step - loss: 0.1766 - accuracy: 0.9598 - val_loss: 0.8528 - val_accuracy: 0.7183\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 10s 46ms/step - loss: 0.1727 - accuracy: 0.9579 - val_loss: 0.8812 - val_accuracy: 0.6964\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 14s 65ms/step - loss: 0.1680 - accuracy: 0.9607 - val_loss: 0.8661 - val_accuracy: 0.7161\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 12s 59ms/step - loss: 0.1673 - accuracy: 0.9584 - val_loss: 0.8712 - val_accuracy: 0.7152\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 15s 73ms/step - loss: 0.1654 - accuracy: 0.9604 - val_loss: 0.8699 - val_accuracy: 0.7232\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 10s 48ms/step - loss: 0.1601 - accuracy: 0.9630 - val_loss: 0.9002 - val_accuracy: 0.6946\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 14s 67ms/step - loss: 0.1611 - accuracy: 0.9609 - val_loss: 0.8978 - val_accuracy: 0.7134\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 13s 63ms/step - loss: 0.1556 - accuracy: 0.9670 - val_loss: 0.8927 - val_accuracy: 0.7094\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 11s 54ms/step - loss: 0.1542 - accuracy: 0.9643 - val_loss: 0.9066 - val_accuracy: 0.7286\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] trainning network...\")\n",
    "#figPath = os.path.sep.join([args[\"output\"], \"{}.png\"].format(os.getpid()))\n",
    "#jsonPath = os.path.sep.join([args[\"output\"], \"{}.json\"].format(os.getpid()))\n",
    "figPath = os.path.sep.join([\"./results\", \"{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([\"./results\", \"{}.json\".format(os.getpid())])\n",
    "callbacks = [TrainingMonitor(figPath, jsonPath=jsonPath)]\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    batch_size=32, epochs=100, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] serializing network...\")\n",
    "#model.save(args[\"model\"])\n",
    "model.save(\"shallownet_animal3_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cane       0.76      0.85      0.80      1216\n",
      "     cavallo       0.70      0.63      0.67       656\n",
      "    elefante       0.63      0.49      0.55       361\n",
      "\n",
      "    accuracy                           0.73      2233\n",
      "   macro avg       0.70      0.66      0.67      2233\n",
      "weighted avg       0.72      0.73      0.72      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "    predictions.argmax(axis=1),\n",
    "    target_names=[str(x) for x in lb.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-44c34a65c0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pDL/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2825\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/miniconda3/envs/pDL/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pDL/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pDL/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (100,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Trainning Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./results/shallownet_animals3_trainning_result_lr_decay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
